{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYcoqyNSkH95",
        "outputId": "02a98e60-acb7-413f-bf48-f283a0cfe801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio\n",
        "!pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "!pip install transformers==4.38.2 accelerate peft datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF-86-B37iTs",
        "outputId": "1f10ef1f-eaac-4ddc-ffe3-56fe67839eec",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "Found existing installation: torchvision 0.21.0+cu124\n",
            "Uninstalling torchvision-0.21.0+cu124:\n",
            "  Successfully uninstalled torchvision-0.21.0+cu124\n",
            "Found existing installation: torchaudio 2.6.0+cu124\n",
            "Uninstalling torchaudio-2.6.0+cu124:\n",
            "  Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (2325.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m998.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.16.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.1.2\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.2%2Bcu118-cp311-cp311-linux_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.2) (2025.3.2)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2)\n",
            "  Downloading https://download.pytorch.org/whl/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.16.2) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.2) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.16.2) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.2) (1.3.0)\n",
            "Installing collected packages: triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "Successfully installed torch-2.1.2+cu118 torchaudio-2.1.2+cu118 torchvision-0.16.2+cu118 triton-2.1.0\n",
            "Collecting transformers==4.38.2\n",
            "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (0.33.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.38.2) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.1.2+cu118)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.38.2) (2025.6.15)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m127.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.1\n",
            "    Uninstalling transformers-4.53.1:\n",
            "      Successfully uninstalled transformers-4.53.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.38.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from datasets import Dataset\n",
        "from datasets.features import Value\n",
        "\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# 1) 데이터 불러오기\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/LLM/train.csv', encoding='utf-8-sig')\n",
        "test_df  = pd.read_csv('/content/drive/MyDrive/LLM/test.csv', encoding='utf-8-sig')\n",
        "\n",
        "# 2) 바로 전체 본문을 입력으로 사용\n",
        "train_df = train_df.rename(columns={'full_text':'text', 'generated':'label'})\n",
        "train_df['label'] = train_df['label'].astype(float)\n",
        "\n",
        "# 3) KFold 세팅\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# 모델 이름 바꾸기\n",
        "MODEL_NAME = 'monologg/kobigbird-bert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# 토큰 길이 분포 확인\n",
        "length_stats = train_df['text'].apply(lambda x: len(tokenizer(x)['input_ids'])).describe()\n",
        "print(\" Token length statistics:\")\n",
        "print(length_stats)"
      ],
      "metadata": {
        "id": "m4ilIsXGhmew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) 토크나이저 함수\n",
        "def tokenize_fn(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        max_length=1024,\n",
        "        truncation=True,\n",
        "        padding='max_length'\n",
        "    )\n",
        "\n",
        "all_fold_preds = []\n",
        "fold_aucs = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['label'])):\n",
        "    print(f\"===== Fold {fold+1}/{n_splits} =====\")\n",
        "\n",
        "    # 5) HuggingFace Dataset 생성\n",
        "    train_fold = Dataset.from_pandas(train_df.iloc[train_idx].reset_index(drop=True))\n",
        "    val_fold   = Dataset.from_pandas(train_df.iloc[val_idx].reset_index(drop=True))\n",
        "    # 칼럼명 변경 및 타입 캐스팅\n",
        "    train_fold = train_fold.rename_column('label', 'labels').cast_column('labels', Value('float32'))\n",
        "    val_fold   = val_fold.rename_column('label', 'labels').cast_column('labels', Value('float32'))\n",
        "\n",
        "    # 6) 토크나이징\n",
        "    train_fold = train_fold.map(tokenize_fn, batched=True)\n",
        "    val_fold   = val_fold.map(tokenize_fn, batched=True)\n",
        "\n",
        "    # 7) 모델 초기화 (회귀)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=1,\n",
        "        problem_type='regression'\n",
        "    )\n",
        "\n",
        "    # 8) 훈련 인자\n",
        "    args = TrainingArguments(\n",
        "        output_dir=f'./outputs/fold{fold}',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=16,\n",
        "        eval_steps=500,\n",
        "        save_steps=500,\n",
        "        logging_steps=200,\n",
        "        learning_rate=2e-5,\n",
        "        weight_decay=0.01,\n",
        "        max_grad_norm=1.0,\n",
        "        warmup_ratio=0.1,\n",
        "        gradient_accumulation_steps=2,\n",
        "        seed=42,\n",
        "        report_to=[\"none\"]\n",
        "    )\n",
        "\n",
        "    # 9) 성능 측정 함수\n",
        "    def compute_metrics(eval_pred):\n",
        "        logits, labels = eval_pred\n",
        "        preds = logits.squeeze()\n",
        "        auc = roc_auc_score(labels, preds)\n",
        "        return {'eval_auc': auc}\n",
        "\n",
        "    # 10) Trainer 선언\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_fold,\n",
        "        eval_dataset=val_fold,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # 11) 학습 & 평가\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    auc_score = metrics.get('eval_auc', 0.0)\n",
        "    fold_aucs.append(auc_score)\n",
        "    print(f\"Fold {fold+1} AUC: {auc_score:.4f}\")\n",
        "\n",
        "    # 12) 검증 예측 저장\n",
        "    val_preds = trainer.predict(val_fold).predictions.squeeze()\n",
        "    train_df.loc[val_idx, 'fold_prob'] = val_preds\n",
        "\n",
        "    # 13) 테스트 예측\n",
        "    test_ds = Dataset.from_pandas(\n",
        "        test_df.rename(columns={'paragraph_text':'text'}).reset_index(drop=True)\n",
        "    ).map(tokenize_fn, batched=True)\n",
        "    test_preds = trainer.predict(test_ds).predictions.squeeze()\n",
        "    all_fold_preds.append(test_preds)\n",
        "\n",
        "# 14) CV 결과 출력\n",
        "avg_auc = float(np.mean(fold_aucs))\n",
        "print(f\"Average CV AUC: {avg_auc:.4f}\")\n",
        "\n",
        "# 15) 제출 파일 생성\n",
        "preds = np.mean(np.vstack(all_fold_preds), axis=0)\n",
        "sample_sub = pd.read_csv('/content/drive/MyDrive/LLM/sample_submission.csv', encoding='utf-8-sig')\n",
        "sample_sub['generated'] = preds\n",
        "\n",
        "submission_path = '/content/drive/MyDrive/LLM/kobigbird-model_seed42.csv'\n",
        "sample_sub.to_csv(submission_path, index=False)\n",
        "\n",
        "# 16) 모델과 토크나이저 저장\n",
        "save_dir = f'/content/drive/MyDrive/LLM/kobigbird-model_seed42/fold{fold}'\n",
        "model.save_pretrained(save_dir)\n",
        "tokenizer.save_pretrained(save_dir)"
      ],
      "metadata": {
        "id": "8mhEiiC4X8pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "T0seNkDoh3vD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}