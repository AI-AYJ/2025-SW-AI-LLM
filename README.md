# LLM-Generated Text Detection

> **ìƒì„± AI(LLM)ê°€ ì‘ì„±í•œ í…ìŠ¤íŠ¸ì™€ ì¸ê°„ì´ ì‘ì„±í•œ í…ìŠ¤íŠ¸ë¥¼ íŒë³„í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ í”„ë¡œì íŠ¸**

[![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python&logoColor=white)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1.2-EE4C2C?logo=pytorch&logoColor=white)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/Transformers-4.38.2-yellow?logo=huggingface&logoColor=white)](https://huggingface.co/)

## 1. Problem Overview ğŸ“‹

ë‰´ìŠ¤ ë° ë¬¸ì„œ í˜•íƒœì˜ ì¥ë¬¸ í…ìŠ¤íŠ¸ê°€ "ì¸ê°„ì— ì˜í•´ ì‘ì„±ë˜ì—ˆëŠ”ì§€" ì•„ë‹ˆë©´ "ìƒì„±í˜• AI ëª¨ë¸ì— ì˜í•´ ì‘ì„±ë˜ì—ˆëŠ”ì§€"ë¥¼ íŒë³„í•˜ëŠ” ê³¼ì œì…ë‹ˆë‹¤.

* **Input:** ë‰´ìŠ¤/ë¬¸ì„œ í˜•íƒœì˜ ì¥ë¬¸ í…ìŠ¤íŠ¸ (ë¬¸ì„œ ê¸¸ì´ í¸ì°¨ê°€ í¼)
* **Key Challenge:** êµ­ì†Œì ì¸ ë¬¸ë²• ì˜¤ë¥˜ë³´ë‹¤ëŠ” **ì „ë°˜ì ì¸ ë¬¸ì„œ êµ¬ì¡°, ë°˜ë³µ íŒ¨í„´, ì„œìˆ  íë¦„** íŒŒì•…ì´ í•µì‹¬
* **Metric:** ROC-AUC

---

## 2. Approach & Strategy 

### 2.1 Baseline: TF-IDF + XGBoost
ì´ˆê¸°ì—ëŠ” í†µê³„ì  ì ‘ê·¼ ë°©ì‹ì„ ì‹œë„í–ˆìœ¼ë‚˜, ìƒì„± AI í…ìŠ¤íŠ¸ì˜ íŠ¹ì„±(í™•ë¥ ì  íŒ¨í„´, ê¸´ ë¬¸ë§¥)ì„ í¬ì°©í•˜ëŠ” ë° í•œê³„ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

* **Structure:** `[Title TF-IDF] + [Full Text TF-IDF]` â†’ `FeatureUnion` â†’ `XGBoost`
* **Limitation:** ë‹¨ì–´ ë¹ˆë„(n-gram) ê¸°ë°˜ íŠ¹ì§•ì€ ë¬¸ë§¥ ì •ë³´ë¥¼ ì†ì‹¤í•˜ë©°, ê¸´ í˜¸í¡ì˜ ìƒì„± íŒ¨í„´ì„ ì¸ì‹í•˜ê¸° ì–´ë ¤ì›€.

### 2.2 Transition to Transformers
ë‹¨ìˆœ í‚¤ì›Œë“œ ë§¤ì¹­ì´ ì•„ë‹Œ **"ë¬¸ì„œ ì „ë°˜ì˜ ìƒì„± íŒ¨í„´ ì¸ì‹"** ë¬¸ì œë¡œ ì¬ì •ì˜í•˜ì—¬ Transformer ê¸°ë°˜ ëª¨ë¸ë¡œ ì „í™˜í–ˆìŠµë‹ˆë‹¤.

* **Focus:** ì „ì²´ ë³¸ë¬¸(`full_text`) í™œìš©
* **Problem Type:** `Regression` (Binary Classificationì´ì§€ë§Œ Logit ê°’ì„ ê·¸ëŒ€ë¡œ í™œìš©í•˜ì—¬ AUC ìµœì í™”)
* **Validation:** Stratified K-Fold (5-fold)

---

## 3. Model Architecture 

ì„œë¡œ ë‹¤ë¥¸ Inductive Biasë¥¼ ê°€ì§„ ë‘ ê°€ì§€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì•™ìƒë¸” íš¨ê³¼ë¥¼ ê·¹ëŒ€í™”í–ˆìŠµë‹ˆë‹¤.

###  Model 1: KoBigBird (Global Context)
* **Role:** Long-Sequence Modeling (ë¬¸ì„œ ì „ì²´ì˜ êµ¬ì¡° ë° íë¦„ íŒŒì•…)
* **Why?** ì¼ë°˜ BERT(512 í† í° ì œí•œ)ë¡œëŠ” ê¸´ ë¬¸ì„œì˜ í›„ë°˜ë¶€ ë¬¸ë§¥ì´ ì†ì‹¤ë¨. Sparse Attentionì„ í†µí•´ ê¸´ ì‹œí€€ìŠ¤(1024) ì²˜ë¦¬.
* **Focus:** ì„œìˆ  êµ¬ì¡°, ë°˜ë³µ íŒ¨í„´, ì „ì—­ì (Global) íŠ¹ì§•

| Setting | Value |
| :--- | :--- |
| **Model** | `monologg/kobigbird-bert-base` |
| **Max Length** | 1024 |
| **Epochs** | 3 |
| **Learning Rate** | 2e-5 |

###  Model 2: KoELECTRA (Local Pattern)
* **Role:** Token-level Discrimination (êµ­ì†Œì  ì´ìƒ íŒ¨í„´ ê°ì§€)
* **Why?** ELECTRAëŠ” "ì´ í† í°ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?"ë¥¼ íŒë³„í•˜ë„ë¡ í•™ìŠµë¨. AI í…ìŠ¤íŠ¸ íŠ¹ìœ ì˜ ì–´ìƒ‰í•œ ì—°ê²°ì´ë‚˜ í™•ë¥  ë¶„í¬ í¬ì°©ì— ìœ ë¦¬.
* **Focus:** ì§§ì€ ë¬¸ë§¥ì—ì„œì˜ ì •ë°€í•œ íŒë³„, êµ­ì†Œì (Local) íŠ¹ì§•

| Setting | Value |
| :--- | :--- |
| **Model** | `monologg/koelectra-base-v3-discriminator` |
| **Max Length** | 256 |
| **Epochs** | 3 |

---
## 4. Ensemble Strategy 

**Soft Voting Ensemble**ì„ í†µí•´ Global íŠ¹ì§•ê³¼ Local íŠ¹ì§•ì„ ê²°í•©í•˜ì˜€ìŠµë‹ˆë‹¤.

```mermaid
graph LR
    A[Input Text] --> B(KoBigBird)
    A[Input Text] --> C(KoELECTRA)
    B -- Global Logic --> D[Prob A]
    C -- Local Logic --> E[Prob B]
    D --> F{Soft Voting}
    E --> F
    F --> G[Final Prediction]
```

### Ensemble Logic
| Model | Viewpoint | Inductive Bias |
| :--- | :--- | :--- |
| **KoBigBird** | Macro (ê±°ì‹œì ) | ë¬¸ì„œ ì „ì²´ êµ¬ì¡°, ê¸´ í˜¸í¡ì˜ ì„œìˆ  íŒ¨í„´ |
| **KoELECTRA** | Micro (ë¯¸ì‹œì ) | í† í° ë‹¨ìœ„ì˜ ìì—°ìŠ¤ëŸ¬ì›€, êµ­ì†Œì  ì´ìƒì¹˜ |

$$\text{Final Probability} = \frac{\text{Prob}_{\text{BigBird}} + \text{Prob}_{\text{Electra}}}{2}$$

---

## 5. Experiment Environment ğŸ› ï¸

### Hardware & Platform
* **Platform:** Google Colab
* **GPU:** NVIDIA GPU (CUDA 11.8)

### Installation
Reproducibilityë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì •ì…ë‹ˆë‹¤.

```bash
# Torch Environment Setup
pip uninstall -y torch torchvision torchaudio
pip install torch==2.1.2 torchvision==0.16.2 torchaudio==2.1.2 \
  --index-url [https://download.pytorch.org/whl/cu118](https://download.pytorch.org/whl/cu118)

# Model Requirements
pip install transformers==4.38.2 accelerate peft datasets
```

---

## 6. Results & Key Takeaways 

### Performance
* **Rank:** Top 26% (72 / 271 Teams) - *Private Leaderboard*
* **Metric:** ROC-AUC

### Insights
1.  **Pattern over Meaning:** ìƒì„± AI íŒë³„ì€ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ëŠ” ê²ƒë³´ë‹¤ ìƒì„± íŒ¨í„´(Generation Artifacts)ì„ ì¸ì‹í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.
2.  **Length Matters:** ê¸´ ë¬¸ì„œì—ì„œëŠ” 512 í† í°ì„ ë„˜ì–´ì„œëŠ” ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ëŠ” Long-sequence ëª¨ë¸(BigBird)ì´ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ í–¥ìƒì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.
3.  **Synergy of Views:** ê±°ì‹œì  ê´€ì (BigBird)ê³¼ ë¯¸ì‹œì  ê´€ì (ELECTRA)ì„ ê²°í•©í•œ ì•™ìƒë¸” ì „ëµì´ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ íš¨ê³¼ì ì´ì—ˆìŠµë‹ˆë‹¤.
4.  **Regression Framing:** Classification ë¬¸ì œë¥¼ Regressionìœ¼ë¡œ ì ‘ê·¼í•˜ì—¬ Logit ê°’ì„ í™œìš©í•œ ê²ƒì´ AUC ì§€í‘œ í•™ìŠµì— ì•ˆì •ì ì´ì—ˆìŠµë‹ˆë‹¤.

---

ğŸ‘‰ ëŒ€íšŒ ì§„í–‰í•˜ë©´ì„œ ì •ë¦¬í•´ë‘” NOTION LINK
* https://www.notion.so/223ff0f0c4c98005ac0aeac60d9fe902?v=223ff0f0c4c9810795a7000c3da7e52f&source=copy_link
